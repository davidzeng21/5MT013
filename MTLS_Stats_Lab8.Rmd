---
title: "Lab 8: Multivariable linear regression & confounding"
output: html_notebook
---
## Part A: Beat AML2 data
```{r}
# load useful packages
library(dplyr)
library(tibble)
library(ggplot2)
library(broom)
library(ggfortify)
library(lmtest)
```

```{r}
# load the data
load("BeatAML2_clean.RData")

# extract just the two genes we are interested in
genes <- c("ENSG00000100221", "ENSG00000000457")
labgenes <- as_tibble(t(rnaNorm[genes,]), rownames = "sample") |> 
    rename(JOSD1 = ENSG00000100221, SCYL3 = ENSG00000000457)

# add patient information (sex)
labdata <- labgenes |> 
    left_join(clinical_data |> select(sample, sex = consensus_sex), by = "sample")
```

### 1. First we will assess sex as a potential confounder. When making this assessment it is better to compare the means (first for JOSD1, then for SCYL3) in each group by sex, rather than performing a formal test. A test could give a low p-value even for a very weak association (if the sample size is large); conversely, a test may fail to detect a strong association fo the sample size is small. Confounding is not affected by the size of the sample.

```{r}
# overall means
labdata |> 
    summarize(across(JOSD1:SCYL3, list("mean" = mean)))
# means by sex
labdata |> 
    group_by(sex) |> 
    summarize(across(JOSD1:SCYL3, list("mean" = mean)))
```

```{r}
# visualize
ggplot(labdata) + geom_boxplot(aes(sex, JOSD1))
ggplot(labdata) + geom_boxplot(aes(sex, SCYL3))
```
a) Is there an association between sex and JOSD1 (the outcome)?
Yes.

b) Is there an association between sex and SCYL3 (the exposure of interest)?
Yes.

c) Based on your answers to (a) and (b), do you expect sex to confound the association between JOSD1 and SCYL3?
Yes.

### 2. Fit a linear regression model for JOSD1 including just SCYL3 as a predictor. Note the effect size and its standard error and associated p-value.

```{r}
summary(mod1 <- lm(JOSD1 ~ SCYL3, data = labdata))

```

### 3. Now add sex to the model (as a binary predictor variable). Think about the following quantities: have they changed, and if so, have the decreased or increased?
a) The estimate of the effect of SYCL3 on JOSD1
The estimate of the effect of SCYL3 on JOSD1 has increased from -0.76081 to -0.76349.
b) The p-value for SCYL3
Shouldn't change much. cannot tell.
c) The standard error for SCYL3
The standard error for SCYL3 has not changed much from 0.05377 to 0.05376.
d) The value of R2 for the model
The value of R2 for the model has increased from 0.3111 to 0.3123.
e) Could you have predicted any of these changes before running the model?
Yes, the estimate of the effect of SCYL3 on JOSD1 should increase.
f) For each of these values, do you think it is better to look at the absolute change or the relative change?
The absolute change is more informative.


```{r}
summary(mod2 <- lm(JOSD1 ~ SCYL3 + sex, data = labdata))
```
### 4. Create a new variable containing the residuals form the model containing both SYCL3 and sex.
a) Do the residuals follow a Normal distribution? Produce a histogram and a QQ plot to help assess this.
Yes.
b) Plot the residuals (y-axis) against the SCYL3 (x-axis). Do you think SCYL3 is correctly specified in the model?
Yes.

```{r}
# residuals
modfit <- augment(mod2, labdata)

ggplot(modfit) + geom_histogram(aes(.resid), bins = 30)
ggplot(modfit, aes(sample = .resid)) + geom_qq() + geom_qq_line()

ggplot(modfit) + geom_point(aes(SCYL3, .resid))

autoplot(mod2) # or ggfortify
```

## Part B: Simulated datasets

### 5. Open the dataset “Lab08_Q5_data.txt”. The data consist of three variables: a continuous exposure X, a binary variable sex (a potential confounder), and a countinuous outcome Y.

```{r}
# load the data
sim1 <- read.table("Lab08_Q5_data-1.txt", header = TRUE)

```


a) Is there a crude association (ie ignoring sex) between X and Y? What is the regression coefficient for the strength of this association? And the p-value for this association? What would you conclude about the association between X and Y?

```{r}
# association
summary(mod3 <- lm(Y ~ X, data = sim1))
```
There is a crude association between X and Y. The regression coefficient is 2.6425 and the p-value is 0.0219. We would conclude that there is an association between X and Y.

b) Look at the assocation between (i) sex and X, and (ii) sex and Y.
Do you think it is possible for sex to confound the X-Y association?
Yes.
```{r}
# overall means
sim1 |> 
    summarize(across(X:Y, list("mean" = mean)))
# means by sex
sim1 |> 
    group_by(sex) |> 
    summarize(across(X:Y, list("mean" = mean)))
# visualize
ggplot(sim1) + geom_bar(aes(factor(sex), fill = factor(X)))
ggplot(sim1) + geom_boxplot(aes(factor(sex), Y))
```

c) Include sex in the linear regression model. Which estimates have changed? How have your conclusions altered?
The estimate of the effect of X on Y has changed from 2.6425 to 2.0481. The p-value has changed from 0.0219 to 0.106. Our conclusions have altered. There is no longer an association between X and Y.
```{r}
summary(mod4 <- lm(Y ~ X + sex, data = sim1))
```

ADVANCED: 
d) Change one of the values of sex to “missing” and re-fit the model. How does the model change? Is this observation included or excluded from the analysis?

```{r}
# change one
sim1$sex[1] <- NA
summary(mod5 <- lm(Y ~ X + sex, data = sim1))
```
The regression coefficient of X increase and the p-value decrease.
The observation is excluded from the analysis.



### 6. Open the dataset “Lab08_Q6_data.txt”. The data consist of three variables: a binary exposure X, a three-level variable Z (a potential confounder), and a countinuous outcome Y.

```{r}
# load the data
sim2 <- read.table("Lab08_Q6_data-1.txt", header = TRUE,
                   colClasses = c("numeric", "numeric", "factor"))

```


a) Investigate the crude association between X and Y. What do you conclude?

```{r}
summary(mod6 <- lm(Y ~ X, data = sim2))
```
There is a crude association between X and Y. The regression coefficient is 0.5930 and the p-value is 0.00988. We would conclude that there is an association between X and Y.


b) Investigate the association between (i) Z and X and (ii) Z and Y. Do you think Z could be a confounder?
Yes.
```{r}
summary(lm(X ~ as.numeric(Z), data = sim2))
summary(lm(Y ~ as.numeric(Z), data = sim2))

ggplot(sim2) + geom_boxplot(aes(Z, X))
ggplot(sim2) + geom_boxplot(aes(Z, Y))
```



c) When you have a categorical variable with more than two levels, you have to decide whether to include it in a model as a linear term (so that the effect of jumping from level 1->2 is the same as jumping from level 2->3). In your research you will use knowledge of the variable to help you decide which is more appropriate, but looking only at the data here, which do you think is more likely? Does Z seem to be acting in a linear way (as Z increases, X increases/decreases, and as Z increases Y increases/decreases)? Or is it acting in a non linear way, so that X (or Y) goes up and then down?

It seems that Z is acting in a non-linear way. As Z increases, X decreases and then increases. 


d) Fit a model including X and Z as a linear variable. Does the inclusion of Z change the estimate for the effect of X on Y?

Yes. the estimate for the effect of X on Y has changed from 0.5930 to 0.4980. The p-value has changed from 0.00988 to 2.37e-05.

```{r}
summary(mod7 <- lm(Y ~ X + as.numeric(Z), data = sim2))
```

e) Fit the model with Z as a categorical variable. How do the estimates for the effect of X change compared to the model in (d)? Perform a global test to see if there is evidence for the effect of X on Y (after adjusting for Z).
It decreases from 0.4980 to 0.03896.
The global test is significant and it shows that there is evidence for the effect of X on Y.

```{r}
# Z as a categorical covariate
summary(mod6 <- lm(Y ~ X + Z, data = sim2))
tidy(drop1(mod6, scope = ~ Z, test = "F"))
```


f) Use a likelihood ratio test to compare the model which includes Z as a categorical variable and the model which includes Z as a linear variable (include X in both models). What do you conclude?

```{r}
lmtest::lrtest(mod7, mod6)
```
The likelihood ratio test is significant and it shows that the model which includes Z as a categorical variable is better than the model which includes Z as a linear variable.


g) Include (or not) Z in your model in the way you think is most appropriate. Write a short paragraph to describe the effect of X on Z, and any confounding effect of Z.

```{r}
summary(mod8 <- lm(Y ~ X + Z, data = sim2))
```
The effect of X on Y is 0.03896. Z is a confounder because it changes the estimate of the effect of X on Y.











